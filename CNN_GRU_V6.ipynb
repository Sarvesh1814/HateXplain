{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDD+J35rgXk/nuArz1LtoQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sarvesh1814/HateXplain/blob/Sarvesh/CNN_GRU_V6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Increased GRU units and decreased no of neurons in 1st layer of ANN structure**\n",
        "\n",
        "**Outcome:- Improvement in Validation Accuracy (Crossed 50% mark)**"
      ],
      "metadata": {
        "id": "rbzdZotODJCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLUfaxMXysON",
        "outputId": "9272d148-8d63-44db-9762-a415fa209267"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, GRU, Dense, Dropout\n",
        "import numpy as np\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from wordcloud import WordCloud\n",
        "from gensim.models import Word2Vec\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "zIZ8Y9UgyTcd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import gensim\n",
        "import spacy\n",
        "import nltk\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, GRU, Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import RMSprop,Adam\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "Q2jm9eXj1Zup"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the pre-trained GloVe word embeddings\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE5EkqhbyWFs",
        "outputId": "2bdd6cf7-7a84-4149-f7de-5b3433d1f5e7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-13 05:55:38--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2023-04-13 05:55:38--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-04-13 05:55:39--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1      100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n",
            "\n",
            "2023-04-13 05:58:18 (5.18 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.50d.txt        \n",
            "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace glove.6B.200d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Reproducibility/Sample Model/HateXplain2.csv\")"
      ],
      "metadata": {
        "id": "1b1yoLDw153l"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df[['post_tokens',\t'Target_cat',\t'Label_cat',\t'final_rationales']]\n",
        "data['post_tokens'] = data['post_tokens'].apply(lambda x: eval(x))\n",
        "for i in range(len(data)):\n",
        "  \n",
        "  sentence =\"\"\n",
        "  for j in (data['post_tokens'].iloc[i]):\n",
        "    \n",
        "    sentence += j +\" \"\n",
        "    \n",
        "  data['post_tokens'].iloc[i] = sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiZs90jR1_uB",
        "outputId": "42f33211-0976-4b3c-bf17-6c52512ef776"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-5f0ee8932d8a>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['post_tokens'] = data['post_tokens'].apply(lambda x: eval(x))\n",
            "<ipython-input-13-5f0ee8932d8a>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['post_tokens'].iloc[i] = sentence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {'hatespeech': 0, 'normal': 1, 'offensive': 2}\n",
        "labels = data[\"Label_cat\"].apply(lambda x: label_map[x])"
      ],
      "metadata": {
        "id": "gNrV0SsR2CTa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y2 = label_encoder.fit_transform(data['Target_cat'])"
      ],
      "metadata": {
        "id": "_bPhgPdIOfdj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 30000\n",
        "maxlen = 100\n",
        "\n",
        "# Tokenize the text data and convert it to sequences of integers\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(df['post_tokens'])\n",
        "sequences = tokenizer.texts_to_sequences(df['post_tokens'])\n",
        "X = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "# Define the target labels\n",
        "y1 = pd.get_dummies(df['Label_cat']).values\n",
        "y2 = to_categorical(y2, num_classes=21)"
      ],
      "metadata": {
        "id": "zNIUNUvv1zmc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFtuaXqNQuvo",
        "outputId": "0f7805e2-b669-4fa4-9119-b4d31ab37dac"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       ...,\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained GloVe embeddings\n",
        "embedding_dict = {}\n",
        "with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_dict[word] = vector\n",
        "\n",
        "# Initialize the embedding matrix with pre-trained GloVe embeddings\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(max_words, len(word_index) + 1)\n",
        "embedding_matrix = np.zeros((num_words, 100))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_words:\n",
        "        continue\n",
        "    embedding_vector = embedding_dict.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n"
      ],
      "metadata": {
        "id": "ftMNfY-u2JkW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Arichtecture"
      ],
      "metadata": {
        "id": "1XAU2Nmp9W45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "from keras.models import Model\n",
        "model1 = Sequential()\n",
        "model1.add(Embedding(num_words, 100, weights=[embedding_matrix], input_length=maxlen, trainable=True))\n",
        "model1.add(Conv1D(64, 7, activation='relu'))\n",
        "model1.add(MaxPooling1D(2))\n",
        "model1.add(Dropout(0.1))\n",
        "model1.add(GRU(128, dropout=0.2, recurrent_dropout=0.1))\n",
        "model1.add(Dense(64, activation='relu'))\n",
        "\n",
        "model2 = Dense(3, activation='softmax')(model1.output)\n",
        "model3 = Dense(21, activation='softmax')(model1.output)\n",
        "\n",
        "model = Model(inputs=model1.input, outputs=[model2, model3])\n",
        "# Compile the model1\n",
        "model.compile(optimizer=RMSprop(lr=1e-2), loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "# Train the model1\n",
        "history=model.fit(X, [y1, y2], epochs=15, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9Dh14KZ5UE4",
        "outputId": "cf6f8781-8451-446f-92f5-05cb74c128af"
      },
      "execution_count": 26,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "504/504 [==============================] - 107s 187ms/step - loss: 2.5978 - dense_10_loss: 0.9158 - dense_11_loss: 1.6820 - dense_10_acc: 0.5722 - dense_11_acc: 0.5246 - val_loss: 2.7801 - val_dense_10_loss: 1.0101 - val_dense_11_loss: 1.7700 - val_dense_10_acc: 0.4593 - val_dense_11_acc: 0.4387\n",
            "Epoch 2/15\n",
            "504/504 [==============================] - 94s 186ms/step - loss: 2.0733 - dense_10_loss: 0.7846 - dense_11_loss: 1.2887 - dense_10_acc: 0.6567 - dense_11_acc: 0.6287 - val_loss: 2.9330 - val_dense_10_loss: 1.1462 - val_dense_11_loss: 1.7868 - val_dense_10_acc: 0.4395 - val_dense_11_acc: 0.4950\n",
            "Epoch 3/15\n",
            "504/504 [==============================] - 94s 186ms/step - loss: 1.9757 - dense_10_loss: 0.7512 - dense_11_loss: 1.2245 - dense_10_acc: 0.6748 - dense_11_acc: 0.6519 - val_loss: 2.7664 - val_dense_10_loss: 0.9874 - val_dense_11_loss: 1.7791 - val_dense_10_acc: 0.5203 - val_dense_11_acc: 0.4978\n",
            "Epoch 4/15\n",
            "504/504 [==============================] - 92s 182ms/step - loss: 1.9430 - dense_10_loss: 0.7317 - dense_11_loss: 1.2113 - dense_10_acc: 0.6848 - dense_11_acc: 0.6560 - val_loss: 2.9531 - val_dense_10_loss: 1.0781 - val_dense_11_loss: 1.8751 - val_dense_10_acc: 0.4864 - val_dense_11_acc: 0.4635\n",
            "Epoch 5/15\n",
            "504/504 [==============================] - 93s 185ms/step - loss: 1.9081 - dense_10_loss: 0.7140 - dense_11_loss: 1.1941 - dense_10_acc: 0.6964 - dense_11_acc: 0.6609 - val_loss: 3.0251 - val_dense_10_loss: 1.0360 - val_dense_11_loss: 1.9891 - val_dense_10_acc: 0.5228 - val_dense_11_acc: 0.4347\n",
            "Epoch 6/15\n",
            "504/504 [==============================] - 97s 193ms/step - loss: 1.9010 - dense_10_loss: 0.6975 - dense_11_loss: 1.2035 - dense_10_acc: 0.7041 - dense_11_acc: 0.6663 - val_loss: 2.8716 - val_dense_10_loss: 1.0167 - val_dense_11_loss: 1.8549 - val_dense_10_acc: 0.5156 - val_dense_11_acc: 0.4583\n",
            "Epoch 7/15\n",
            "504/504 [==============================] - 93s 184ms/step - loss: 1.9490 - dense_10_loss: 0.7026 - dense_11_loss: 1.2464 - dense_10_acc: 0.7042 - dense_11_acc: 0.6569 - val_loss: 3.1422 - val_dense_10_loss: 1.1144 - val_dense_11_loss: 2.0278 - val_dense_10_acc: 0.4846 - val_dense_11_acc: 0.4380\n",
            "Epoch 8/15\n",
            "504/504 [==============================] - 91s 180ms/step - loss: 1.9377 - dense_10_loss: 0.7064 - dense_11_loss: 1.2313 - dense_10_acc: 0.7001 - dense_11_acc: 0.6619 - val_loss: 3.5691 - val_dense_10_loss: 1.2307 - val_dense_11_loss: 2.3383 - val_dense_10_acc: 0.4648 - val_dense_11_acc: 0.4623\n",
            "Epoch 9/15\n",
            "504/504 [==============================] - 94s 186ms/step - loss: 1.9572 - dense_10_loss: 0.7033 - dense_11_loss: 1.2539 - dense_10_acc: 0.6997 - dense_11_acc: 0.6601 - val_loss: 3.4007 - val_dense_10_loss: 1.1538 - val_dense_11_loss: 2.2469 - val_dense_10_acc: 0.5000 - val_dense_11_acc: 0.4824\n",
            "Epoch 10/15\n",
            "504/504 [==============================] - 94s 187ms/step - loss: 1.9829 - dense_10_loss: 0.7086 - dense_11_loss: 1.2743 - dense_10_acc: 0.6983 - dense_11_acc: 0.6512 - val_loss: 3.6349 - val_dense_10_loss: 1.2558 - val_dense_11_loss: 2.3791 - val_dense_10_acc: 0.4792 - val_dense_11_acc: 0.4449\n",
            "Epoch 11/15\n",
            "504/504 [==============================] - 91s 181ms/step - loss: 2.0308 - dense_10_loss: 0.7126 - dense_11_loss: 1.3183 - dense_10_acc: 0.7014 - dense_11_acc: 0.6463 - val_loss: 3.5386 - val_dense_10_loss: 1.1813 - val_dense_11_loss: 2.3574 - val_dense_10_acc: 0.4921 - val_dense_11_acc: 0.4777\n",
            "Epoch 12/15\n",
            "504/504 [==============================] - 100s 198ms/step - loss: 1.9525 - dense_10_loss: 0.7022 - dense_11_loss: 1.2502 - dense_10_acc: 0.7028 - dense_11_acc: 0.6588 - val_loss: 3.2745 - val_dense_10_loss: 1.1371 - val_dense_11_loss: 2.1375 - val_dense_10_acc: 0.4988 - val_dense_11_acc: 0.4295\n",
            "Epoch 13/15\n",
            "504/504 [==============================] - 96s 191ms/step - loss: 1.9632 - dense_10_loss: 0.7012 - dense_11_loss: 1.2620 - dense_10_acc: 0.7034 - dense_11_acc: 0.6575 - val_loss: 3.5397 - val_dense_10_loss: 1.2013 - val_dense_11_loss: 2.3384 - val_dense_10_acc: 0.4834 - val_dense_11_acc: 0.4114\n",
            "Epoch 14/15\n",
            "504/504 [==============================] - 90s 179ms/step - loss: 1.9858 - dense_10_loss: 0.7078 - dense_11_loss: 1.2781 - dense_10_acc: 0.7024 - dense_11_acc: 0.6537 - val_loss: 3.3523 - val_dense_10_loss: 1.1845 - val_dense_11_loss: 2.1678 - val_dense_10_acc: 0.4881 - val_dense_11_acc: 0.4692\n",
            "Epoch 15/15\n",
            "504/504 [==============================] - 91s 180ms/step - loss: 1.9995 - dense_10_loss: 0.7101 - dense_11_loss: 1.2894 - dense_10_acc: 0.7002 - dense_11_acc: 0.6566 - val_loss: 3.0801 - val_dense_10_loss: 1.0468 - val_dense_11_loss: 2.0333 - val_dense_10_acc: 0.5002 - val_dense_11_acc: 0.4407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history"
      ],
      "metadata": {
        "id": "788MZagwYeUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted labels\n",
        "y_pred1, y_pred2 = model.predict(X)\n",
        "\n",
        "# Convert the labels from one-hot encoding to integers\n",
        "y_pred1 = np.argmax(y_pred1, axis=1)\n",
        "y_pred2 = np.argmax(y_pred2, axis=1)\n",
        "y_test_int1 = np.argmax(y1, axis=1)\n",
        "y_test_int2 = np.argmax(y2, axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAR3_Jxwaa6i",
        "outputId": "169cc04b-b4f8-4764-aa40-3326c34f0abb"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "630/630 [==============================] - 16s 26ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification report for model2:\")\n",
        "print(classification_report(y_test_int2,y_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUyyHYFQalM9",
        "outputId": "7b44763a-09fe-435d-f784-615817668595"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for model2:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.78      0.78      3037\n",
            "           1       0.00      0.00      0.00       583\n",
            "           2       0.00      0.00      0.00       326\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.00      0.00      0.00       334\n",
            "           5       0.00      0.00      0.00        33\n",
            "           6       0.00      0.00      0.00        48\n",
            "           7       0.00      0.00      0.00        10\n",
            "           8       0.00      0.00      0.00        15\n",
            "           9       0.40      0.66      0.50       222\n",
            "          10       0.80      0.61      0.70      1576\n",
            "          11       0.00      0.00      0.00         8\n",
            "          12       0.00      0.00      0.00         4\n",
            "          13       0.52      0.81      0.63      1633\n",
            "          14       0.92      0.55      0.69      1424\n",
            "          15       0.00      0.00      0.00        89\n",
            "          16       0.00      0.00      0.00         9\n",
            "          17       0.57      0.85      0.68      7109\n",
            "          18       0.09      0.00      0.01      1218\n",
            "          19       0.76      0.57      0.65       962\n",
            "          20       0.75      0.35      0.48      1507\n",
            "\n",
            "    accuracy                           0.63     20148\n",
            "   macro avg       0.27      0.25      0.24     20148\n",
            "weighted avg       0.59      0.63      0.59     20148\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification report for model3:\")\n",
        "print(classification_report(y_test_int1,y_pred1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_FntwmwaxiD",
        "outputId": "88b5b9fd-fa22-47d6-8e12-97d5ffdf0a76"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for model3:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.72      0.75      5934\n",
            "           1       0.73      0.70      0.72      7814\n",
            "           2       0.55      0.62      0.58      6400\n",
            "\n",
            "    accuracy                           0.68     20148\n",
            "   macro avg       0.69      0.68      0.68     20148\n",
            "weighted avg       0.69      0.68      0.68     20148\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save(\"/content/drive/MyDrive/Reproducibility/CNN_GRU_V5.h5\")"
      ],
      "metadata": {
        "id": "I3Dp3BCFLQAl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}