{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeGMd3WpF6sPxbBD/6Ti5U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sarvesh1814/HateXplain/blob/Sarvesh/CNN_GRU_V8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLUfaxMXysON",
        "outputId": "72aff49f-4861-4c94-da21-833ed2c50138"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, GRU, Dense, Dropout\n",
        "from nltk.tokenize import word_tokenize\n",
        "from wordcloud import WordCloud\n",
        "from gensim.models import Word2Vec\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "zIZ8Y9UgyTcd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import gensim\n",
        "import spacy\n",
        "import nltk\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, GRU, Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import RMSprop,Adam\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "Q2jm9eXj1Zup"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the pre-trained GloVe word embeddings\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "metadata": {
        "id": "HE5EkqhbyWFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87174e29-d136-4094-f89f-220558655a2a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-14 10:05:05--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2023-04-14 10:05:06--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-04-14 10:05:06--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n",
            "\n",
            "2023-04-14 10:07:45 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Reproducibility/Sample Model/HateXplain2.csv\")"
      ],
      "metadata": {
        "id": "1b1yoLDw153l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df[['post_tokens',\t'Target_cat',\t'Label_cat',\t'final_rationales']]"
      ],
      "metadata": {
        "id": "-WmlKWTsOLOI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5rsewStWOM-I",
        "outputId": "1e2f6119-4855-4381-ab1f-a87cc9d4002e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         post_tokens Target_cat   Label_cat  \\\n",
              "0  ['i', 'dont', 'think', 'im', 'getting', 'my', ...       None      normal   \n",
              "1  ['we', 'cannot', 'continue', 'calling', 'ourse...       None      normal   \n",
              "2      ['nawt', 'yall', 'niggers', 'ignoring', 'me']    African      normal   \n",
              "3  ['<user>', 'i', 'am', 'bit', 'confused', 'coz'...      Asian  hatespeech   \n",
              "4  ['this', 'bitch', 'in', 'whataburger', 'eating...      Women  hatespeech   \n",
              "\n",
              "                                    final_rationales  \n",
              "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "2                                    [0, 0, 0, 0, 0]  \n",
              "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "4  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c131c871-7a42-4c99-bde5-9e6d2f295dd1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>post_tokens</th>\n",
              "      <th>Target_cat</th>\n",
              "      <th>Label_cat</th>\n",
              "      <th>final_rationales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['i', 'dont', 'think', 'im', 'getting', 'my', ...</td>\n",
              "      <td>None</td>\n",
              "      <td>normal</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['we', 'cannot', 'continue', 'calling', 'ourse...</td>\n",
              "      <td>None</td>\n",
              "      <td>normal</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['nawt', 'yall', 'niggers', 'ignoring', 'me']</td>\n",
              "      <td>African</td>\n",
              "      <td>normal</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['&lt;user&gt;', 'i', 'am', 'bit', 'confused', 'coz'...</td>\n",
              "      <td>Asian</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['this', 'bitch', 'in', 'whataburger', 'eating...</td>\n",
              "      <td>Women</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c131c871-7a42-4c99-bde5-9e6d2f295dd1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c131c871-7a42-4c99-bde5-9e6d2f295dd1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c131c871-7a42-4c99-bde5-9e6d2f295dd1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['post_tokens'] = data['post_tokens'].apply(lambda x: eval(x))\n"
      ],
      "metadata": {
        "id": "ROgsS_HZORUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df[['post_tokens',\t'Target_cat',\t'Label_cat',\t'final_rationales']]\n",
        "data['post_tokens'] = data['post_tokens'].apply(lambda x: eval(x))\n",
        "for i in range(len(data)):\n",
        "  \n",
        "  sentence =\"\"\n",
        "  for j in (data['post_tokens'].iloc[i]):\n",
        "    \n",
        "    sentence += j +\" \"\n",
        "    \n",
        "  data['post_tokens'].iloc[i] = sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiZs90jR1_uB",
        "outputId": "7729d12c-26ea-483f-adf0-ba491dc29e2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-5f0ee8932d8a>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['post_tokens'] = data['post_tokens'].apply(lambda x: eval(x))\n",
            "<ipython-input-6-5f0ee8932d8a>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['post_tokens'].iloc[i] = sentence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {'hatespeech': 2, 'normal': 0, 'offensive': 1}\n",
        "labels = data[\"Label_cat\"].apply(lambda x: label_map[x])"
      ],
      "metadata": {
        "id": "gNrV0SsR2CTa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y2 = label_encoder.fit_transform(data['Target_cat'])"
      ],
      "metadata": {
        "id": "_bPhgPdIOfdj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 30000\n",
        "maxlen = 100\n",
        "\n",
        "# Tokenize the text data and convert it to sequences of integers\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(df['post_tokens'])\n",
        "sequences = tokenizer.texts_to_sequences(df['post_tokens'])\n",
        "X = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "# Define the target labels\n",
        "y1 = pd.get_dummies(df['Label_cat']).values\n",
        "y2 = to_categorical(y2, num_classes=21)"
      ],
      "metadata": {
        "id": "zNIUNUvv1zmc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained GloVe embeddings\n",
        "embedding_dict = {}\n",
        "with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_dict[word] = vector\n",
        "\n",
        "# Initialize the embedding matrix with pre-trained GloVe embeddings\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(max_words, len(word_index) + 1)\n",
        "embedding_matrix = np.zeros((num_words, 100))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_words:\n",
        "        continue\n",
        "    embedding_vector = embedding_dict.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n"
      ],
      "metadata": {
        "id": "ftMNfY-u2JkW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Arichtecture"
      ],
      "metadata": {
        "id": "1XAU2Nmp9W45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Embedding(num_words, 100, weights=[embedding_matrix], input_length=maxlen, trainable=True))\n",
        "model1.add(Conv1D(64, 7, activation='relu'))\n",
        "model1.add(MaxPooling1D(2))\n",
        "model1.add(Dropout(0.1))\n",
        "model1.add(GRU(128, recurrent_dropout=0.01))\n",
        "model1.add(Dense(256, activation='relu'))\n",
        "model1.add(Dense(128, activation='relu'))\n",
        "model1.add(Dense(64, activation='relu'))\n",
        "model2 = Dense(3, activation='softmax')(model1.output)\n",
        "model3 = Dense(21, activation='softmax')(model1.output)\n",
        "\n",
        "model = Model(inputs=model1.input, outputs=[model2, model3])\n",
        "# Compile the model1\n",
        "model.compile(optimizer=RMSprop(lr=1e-3), loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "# Train the model1\n",
        "history=model.fit(X, [y1, y2], epochs=15, batch_size=32, validation_split=0.3)"
      ],
      "metadata": {
        "id": "P9Dh14KZ5UE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee97c95a-270d-4608-9ba9-7b61d015a7e6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "441/441 [==============================] - 89s 189ms/step - loss: 2.6899 - dense_3_loss: 0.9024 - dense_4_loss: 1.7875 - dense_3_acc: 0.5798 - dense_4_acc: 0.4948 - val_loss: 3.4256 - val_dense_3_loss: 1.0669 - val_dense_4_loss: 2.3587 - val_dense_3_acc: 0.4243 - val_dense_4_acc: 0.2842\n",
            "Epoch 2/15\n",
            "441/441 [==============================] - 81s 182ms/step - loss: 2.1163 - dense_3_loss: 0.7213 - dense_4_loss: 1.3950 - dense_3_acc: 0.6903 - dense_4_acc: 0.5950 - val_loss: 3.7041 - val_dense_3_loss: 1.3030 - val_dense_4_loss: 2.4011 - val_dense_3_acc: 0.4225 - val_dense_4_acc: 0.3196\n",
            "Epoch 3/15\n",
            "441/441 [==============================] - 82s 187ms/step - loss: 1.8005 - dense_3_loss: 0.6518 - dense_4_loss: 1.1487 - dense_3_acc: 0.7222 - dense_4_acc: 0.6663 - val_loss: 3.0117 - val_dense_3_loss: 1.0700 - val_dense_4_loss: 1.9417 - val_dense_3_acc: 0.4821 - val_dense_4_acc: 0.4248\n",
            "Epoch 4/15\n",
            "441/441 [==============================] - 80s 181ms/step - loss: 1.5812 - dense_3_loss: 0.5955 - dense_4_loss: 0.9856 - dense_3_acc: 0.7459 - dense_4_acc: 0.7050 - val_loss: 3.4175 - val_dense_3_loss: 1.2048 - val_dense_4_loss: 2.2127 - val_dense_3_acc: 0.4794 - val_dense_4_acc: 0.4184\n",
            "Epoch 5/15\n",
            "441/441 [==============================] - 78s 178ms/step - loss: 1.4132 - dense_3_loss: 0.5419 - dense_4_loss: 0.8713 - dense_3_acc: 0.7752 - dense_4_acc: 0.7357 - val_loss: 3.4754 - val_dense_3_loss: 1.2774 - val_dense_4_loss: 2.1979 - val_dense_3_acc: 0.4733 - val_dense_4_acc: 0.4126\n",
            "Epoch 6/15\n",
            "441/441 [==============================] - 79s 180ms/step - loss: 1.2480 - dense_3_loss: 0.4869 - dense_4_loss: 0.7611 - dense_3_acc: 0.7960 - dense_4_acc: 0.7669 - val_loss: 3.0782 - val_dense_3_loss: 1.1255 - val_dense_4_loss: 1.9528 - val_dense_3_acc: 0.5097 - val_dense_4_acc: 0.4642\n",
            "Epoch 7/15\n",
            "441/441 [==============================] - 80s 180ms/step - loss: 1.1013 - dense_3_loss: 0.4327 - dense_4_loss: 0.6686 - dense_3_acc: 0.8206 - dense_4_acc: 0.7957 - val_loss: 3.5959 - val_dense_3_loss: 1.2861 - val_dense_4_loss: 2.3098 - val_dense_3_acc: 0.4840 - val_dense_4_acc: 0.4364\n",
            "Epoch 8/15\n",
            "441/441 [==============================] - 80s 181ms/step - loss: 0.9774 - dense_3_loss: 0.3897 - dense_4_loss: 0.5877 - dense_3_acc: 0.8406 - dense_4_acc: 0.8159 - val_loss: 3.7789 - val_dense_3_loss: 1.4387 - val_dense_4_loss: 2.3402 - val_dense_3_acc: 0.4637 - val_dense_4_acc: 0.4394\n",
            "Epoch 9/15\n",
            "441/441 [==============================] - 82s 185ms/step - loss: 0.8436 - dense_3_loss: 0.3373 - dense_4_loss: 0.5063 - dense_3_acc: 0.8604 - dense_4_acc: 0.8404 - val_loss: 3.9180 - val_dense_3_loss: 1.4828 - val_dense_4_loss: 2.4353 - val_dense_3_acc: 0.4902 - val_dense_4_acc: 0.4614\n",
            "Epoch 10/15\n",
            "441/441 [==============================] - 79s 180ms/step - loss: 0.7434 - dense_3_loss: 0.3016 - dense_4_loss: 0.4417 - dense_3_acc: 0.8767 - dense_4_acc: 0.8639 - val_loss: 3.9639 - val_dense_3_loss: 1.4577 - val_dense_4_loss: 2.5061 - val_dense_3_acc: 0.4897 - val_dense_4_acc: 0.4382\n",
            "Epoch 11/15\n",
            "441/441 [==============================] - 84s 191ms/step - loss: 0.6494 - dense_3_loss: 0.2586 - dense_4_loss: 0.3909 - dense_3_acc: 0.8955 - dense_4_acc: 0.8800 - val_loss: 4.3494 - val_dense_3_loss: 1.6398 - val_dense_4_loss: 2.7095 - val_dense_3_acc: 0.4996 - val_dense_4_acc: 0.4617\n",
            "Epoch 12/15\n",
            "441/441 [==============================] - 81s 183ms/step - loss: 0.5755 - dense_3_loss: 0.2312 - dense_4_loss: 0.3442 - dense_3_acc: 0.9076 - dense_4_acc: 0.8929 - val_loss: 4.5457 - val_dense_3_loss: 1.6522 - val_dense_4_loss: 2.8935 - val_dense_3_acc: 0.5135 - val_dense_4_acc: 0.4445\n",
            "Epoch 13/15\n",
            "441/441 [==============================] - 85s 194ms/step - loss: 0.4976 - dense_3_loss: 0.1954 - dense_4_loss: 0.3023 - dense_3_acc: 0.9236 - dense_4_acc: 0.9046 - val_loss: 4.6199 - val_dense_3_loss: 1.7841 - val_dense_4_loss: 2.8358 - val_dense_3_acc: 0.4978 - val_dense_4_acc: 0.4331\n",
            "Epoch 14/15\n",
            "441/441 [==============================] - 86s 196ms/step - loss: 0.4358 - dense_3_loss: 0.1736 - dense_4_loss: 0.2623 - dense_3_acc: 0.9307 - dense_4_acc: 0.9158 - val_loss: 5.8275 - val_dense_3_loss: 2.1266 - val_dense_4_loss: 3.7009 - val_dense_3_acc: 0.5011 - val_dense_4_acc: 0.4294\n",
            "Epoch 15/15\n",
            "441/441 [==============================] - 81s 185ms/step - loss: 0.3927 - dense_3_loss: 0.1502 - dense_4_loss: 0.2425 - dense_3_acc: 0.9399 - dense_4_acc: 0.9253 - val_loss: 5.6762 - val_dense_3_loss: 2.1306 - val_dense_4_loss: 3.5456 - val_dense_3_acc: 0.4999 - val_dense_4_acc: 0.4184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted labels\n",
        "y_pred1, y_pred2 = model.predict(X)\n",
        "\n",
        "# Convert the labels from one-hot encoding to integers\n",
        "y_pred1 = np.argmax(y_pred1, axis=1)\n",
        "y_pred2 = np.argmax(y_pred2, axis=1)\n",
        "y_test_int1 = np.argmax(y1, axis=1)\n",
        "y_test_int2 = np.argmax(y2, axis=1)\n"
      ],
      "metadata": {
        "id": "iAR3_Jxwaa6i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb01929c-190d-45c7-84b2-c2e09ced8ac6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "630/630 [==============================] - 17s 27ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification report for model2:\")\n",
        "print(classification_report(y_test_int2,y_pred2))"
      ],
      "metadata": {
        "id": "vUyyHYFQalM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79b33561-f470-4540-fd08-0345559efbb4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for model2:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.89      0.85      3037\n",
            "           1       0.76      0.57      0.66       583\n",
            "           2       0.68      0.68      0.68       326\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.24      0.58      0.34       334\n",
            "           5       0.00      0.00      0.00        33\n",
            "           6       0.20      0.23      0.21        48\n",
            "           7       0.00      0.00      0.00        10\n",
            "           8       0.00      0.00      0.00        15\n",
            "           9       0.98      0.83      0.90       222\n",
            "          10       0.93      0.73      0.82      1576\n",
            "          11       0.00      0.00      0.00         8\n",
            "          12       0.00      0.00      0.00         4\n",
            "          13       0.83      0.76      0.79      1633\n",
            "          14       0.89      0.83      0.86      1424\n",
            "          15       0.00      0.00      0.00        89\n",
            "          16       0.00      0.00      0.00         9\n",
            "          17       0.86      0.85      0.86      7109\n",
            "          18       0.46      0.55      0.50      1218\n",
            "          19       0.75      0.74      0.74       962\n",
            "          20       0.79      0.79      0.79      1507\n",
            "\n",
            "    accuracy                           0.79     20148\n",
            "   macro avg       0.44      0.43      0.43     20148\n",
            "weighted avg       0.80      0.79      0.79     20148\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification report for model3:\")\n",
        "print(classification_report(y_test_int1,y_pred1))"
      ],
      "metadata": {
        "id": "x_FntwmwaxiD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fae7ab4-82ee-4687-d788-812ba1419a09"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for model3:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.84      0.83      5934\n",
            "           1       0.87      0.85      0.86      7814\n",
            "           2       0.74      0.75      0.75      6400\n",
            "\n",
            "    accuracy                           0.82     20148\n",
            "   macro avg       0.81      0.81      0.81     20148\n",
            "weighted avg       0.82      0.82      0.82     20148\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/Reproducibility/CNN_GRU2.h5\")"
      ],
      "metadata": {
        "id": "WhPD35P7glXx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence =  \"He is a bloody indian terrorist\"\n",
        "sentence = sentence.lower()\n",
        "input_seq = tokenizer.texts_to_sequences([sentence])\n",
        "input_seq = pad_sequences(input_seq, maxlen=maxlen)\n",
        "\n",
        "# Predict the output\n",
        "output = model.predict(input_seq)\n",
        "\n",
        "# Extract the predictions for each task\n",
        "prediction1 = np.argmax(output[0])\n",
        "prediction2 = np.argmax(output[1])\n",
        "label_maps = {2: 'hatespeech', 0: 'normal', 1: 'offensive'}\n",
        "# Print the predictions\n",
        "print(\"Prediction for task 1:\", label_maps[prediction1])\n",
        "print(\"Prediction for task 2:\", label_encoder.inverse_transform([prediction2]))"
      ],
      "metadata": {
        "id": "lEUT0jVRgYYV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23bf0347-9666-4624-f990-ff619c14c414"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 74ms/step\n",
            "Prediction for task 1: hatespeech\n",
            "Prediction for task 2: ['Asian']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: This examples are taken to just check the working of model. It is not to abuse anyone."
      ],
      "metadata": {
        "id": "A1BlkFXONByg"
      }
    }
  ]
}