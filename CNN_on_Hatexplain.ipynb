{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import gensim\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from wordcloud import WordCloud\n",
        "from gensim.models import Word2Vec\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
        "import tensorflow as tf\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "2TYmN_uB106u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8DEUDESq4yD",
        "outputId": "f2fb81d1-467d-4698-cb2b-1869f9106756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Reproducibility/Sample Model/HateXplain2.csv\")"
      ],
      "metadata": {
        "id": "nExxJ6cn1qGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['post_tokens',\t'Target_cat',\t'Label_cat',\t'final_rationales']]\n",
        "df['post_tokens'] = df['post_tokens'].apply(lambda x: eval(x))\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nkqBN6Pa1wKA",
        "outputId": "f1c0e8fd-55d7-4e4a-9954-3147d58fd6d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         post_tokens Target_cat   Label_cat  \\\n",
              "0  [i, dont, think, im, getting, my, baby, them, ...       None      normal   \n",
              "1  [we, cannot, continue, calling, ourselves, fem...       None      normal   \n",
              "2                [nawt, yall, niggers, ignoring, me]    African      normal   \n",
              "3  [<user>, i, am, bit, confused, coz, chinese, p...      Asian  hatespeech   \n",
              "4  [this, bitch, in, whataburger, eating, a, burg...      Women  hatespeech   \n",
              "\n",
              "                                    final_rationales  \n",
              "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "2                                    [0, 0, 0, 0, 0]  \n",
              "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "4  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35ea3a84-79d2-41d7-9508-5583798df250\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>post_tokens</th>\n",
              "      <th>Target_cat</th>\n",
              "      <th>Label_cat</th>\n",
              "      <th>final_rationales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[i, dont, think, im, getting, my, baby, them, ...</td>\n",
              "      <td>None</td>\n",
              "      <td>normal</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[we, cannot, continue, calling, ourselves, fem...</td>\n",
              "      <td>None</td>\n",
              "      <td>normal</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[nawt, yall, niggers, ignoring, me]</td>\n",
              "      <td>African</td>\n",
              "      <td>normal</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[&lt;user&gt;, i, am, bit, confused, coz, chinese, p...</td>\n",
              "      <td>Asian</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[this, bitch, in, whataburger, eating, a, burg...</td>\n",
              "      <td>Women</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35ea3a84-79d2-41d7-9508-5583798df250')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-35ea3a84-79d2-41d7-9508-5583798df250 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-35ea3a84-79d2-41d7-9508-5583798df250');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [tweet for tweet in df['post_tokens']]"
      ],
      "metadata": {
        "id": "0qNRHbHF2rtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_WV = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=5, workers=4, sg=0)\n",
        "\n",
        "# Save Word2Vec model\n",
        "model_WV.save('/content/drive/MyDrive/Reproducibility/Test_model/word2vec_model')"
      ],
      "metadata": {
        "id": "VbwqoQGl3Jg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors = model_WV.wv"
      ],
      "metadata": {
        "id": "cZG840mc39Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = len(word_vectors.key_to_index.keys())\n",
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "for i, word in enumerate(word_vectors.index_to_key):\n",
        "    embedding_vector = word_vectors[word]\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "0WrLFDHJ4DWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_encoder = LabelEncoder()\n",
        "target_labels = target_encoder.fit_transform(df['Target_cat'])\n",
        "y1 = tf.keras.utils.to_categorical(target_labels, num_classes=21)\n",
        "Label_encoder = LabelEncoder()\n",
        "Label_labels = Label_encoder.fit_transform(df['Label_cat'])\n",
        "y2 = tf.keras.utils.to_categorical(Label_labels, num_classes=3)"
      ],
      "metadata": {
        "id": "M2zzPxme8i_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = []\n",
        "for tweet in df['post_tokens']:\n",
        "    sequence = []\n",
        "    for word in tweet:\n",
        "        if word in model_WV.wv:\n",
        "            sequence.append(model_WV.wv[word])\n",
        "    sequences.append(sequence)"
      ],
      "metadata": {
        "id": "dqQLl5UB62UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y1_train, y1_test, y2_train, y2_test = train_test_split(sequences, y1, y2, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "5ezMyZw8jJfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences to a fixed length\n",
        "max_sequence_length = 100\n",
        "padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_sequence_length, padding='post', truncating='post')\n",
        "padded_sequences_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_sequence_length, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "pl13_CkF7X4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = padded_sequences\n",
        "x_test = padded_sequences_test"
      ],
      "metadata": {
        "id": "MjcO2Evknns1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, GlobalMaxPooling1D, Concatenate, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "\n",
        "def build_model(max_sequence_length, embedding_dim, num_classes_community, num_classes_label):\n",
        "    \n",
        "    input_layer = Input(shape=(max_sequence_length, embedding_dim))\n",
        "    conv_layer1 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "    batch_norm1 = BatchNormalization()(conv_layer1)\n",
        "    conv_layer2 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(batch_norm1)\n",
        "    batch_norm2 = BatchNormalization()(conv_layer2)\n",
        "\n",
        "    skip_layer1 = Concatenate()([batch_norm1, batch_norm2])\n",
        "    conv_layer3 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(skip_layer1)\n",
        "    batch_norm3 = BatchNormalization()(conv_layer3)\n",
        "\n",
        "    skip_layer2 = Concatenate()([batch_norm2, batch_norm3])\n",
        "    conv_layer4 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(skip_layer2)\n",
        "    batch_norm4 = BatchNormalization()(conv_layer4)\n",
        "\n",
        "    skip_layer3 = Concatenate()([batch_norm3, batch_norm3])\n",
        "    conv_layer5 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(skip_layer3)\n",
        "    batch_norm5 = BatchNormalization()(conv_layer5)\n",
        "\n",
        "    skip_layer4 = Concatenate()([batch_norm4, batch_norm5])\n",
        "    conv_layer6 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(skip_layer4)\n",
        "    batch_norm6 = BatchNormalization()(conv_layer6)\n",
        "\n",
        "    drop1 = Dropout(0.5)(batch_norm6)\n",
        "    pool_layer1 = MaxPooling1D(pool_size=5)(drop1)\n",
        "\n",
        "\n",
        "    flatten_layer = Flatten()(pool_layer1)\n",
        "\n",
        "    dense_layer1 = Dense(64, activation='relu')(flatten_layer)\n",
        "    batch_norm7 = BatchNormalization()(dense_layer1)\n",
        "    drop2 = Dropout(0.5)(batch_norm7)\n",
        "    dense_layer2 = Dense(64, activation='relu')(drop2)\n",
        "    batch_norm8 = BatchNormalization()(dense_layer2)\n",
        "    drop3 = Dropout(0.5)(batch_norm8)\n",
        "    dense_layer3 = Dense(32, activation='relu')(drop2)\n",
        "    batch_norm9 = BatchNormalization()(dense_layer3)\n",
        "    drop4 = Dropout(0.5)(batch_norm9)\n",
        "  \n",
        "    dense_layer4 = Dense(64, activation='relu')(flatten_layer)\n",
        "    batch_norm10 = BatchNormalization()(dense_layer4)\n",
        "    drop5 = Dropout(0.5)(batch_norm10)\n",
        "    dense_layer5 = Dense(64, activation='relu')(drop5)\n",
        "    batch_norm11 = BatchNormalization()(dense_layer5)\n",
        "    drop6 = Dropout(0.5)(batch_norm11)\n",
        "    dense_layer6 = Dense(32, activation='relu')(drop5)\n",
        "    batch_norm12 = BatchNormalization()(dense_layer6)\n",
        "    drop7 = Dropout(0.5)(batch_norm12)\n",
        "\n",
        "    # Define the output layers\n",
        "    output_community = Dense(num_classes_community, activation='softmax', name='community_output')(drop4)\n",
        "    output_label = Dense(num_classes_label, activation='softmax', name='label_output')(drop7)\n",
        "\n",
        "    # Compile the model with the custom loss function\n",
        "    model = Model(inputs=input_layer, outputs=[output_community, output_label])\n",
        "    model.compile(loss={'community_output': categorical_crossentropy,\n",
        "                        'label_output': categorical_crossentropy},\n",
        "                  optimizer='adam',\n",
        "                  metrics={'community_output': 'accuracy',\n",
        "                           'label_output': 'accuracy'})\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "PdNtjVgXlkCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HWdoJxwvkDu",
        "outputId": "c740aeaf-272c-4395-d4be-d44412b7eb14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16118, 100, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(max_sequence_length, embedding_dim, num_classes_community = 21, num_classes_label = 3 )"
      ],
      "metadata": {
        "id": "FxNODDd9rXPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x= x_train, y = {'community_output': y1_train, 'label_output': y2_train}, validation_data = (x_test, {'community_output': y1_test, 'label_output': y2_test}), batch_size = 50, epochs = 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yxk6WgQzsbAz",
        "outputId": "8644b4c2-50ac-4530-83a8-97e503711e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "323/323 [==============================] - 17s 23ms/step - loss: 4.6409 - community_output_loss: 3.1594 - label_output_loss: 1.4815 - community_output_accuracy: 0.1818 - label_output_accuracy: 0.3447 - val_loss: 3.4734 - val_community_output_loss: 2.3665 - val_label_output_loss: 1.1069 - val_community_output_accuracy: 0.3375 - val_label_output_accuracy: 0.3400\n",
            "Epoch 2/50\n",
            "323/323 [==============================] - 5s 16ms/step - loss: 3.5222 - community_output_loss: 2.3856 - label_output_loss: 1.1367 - community_output_accuracy: 0.3114 - label_output_accuracy: 0.3777 - val_loss: 3.1979 - val_community_output_loss: 2.1307 - val_label_output_loss: 1.0672 - val_community_output_accuracy: 0.3417 - val_label_output_accuracy: 0.4045\n",
            "Epoch 3/50\n",
            "323/323 [==============================] - 6s 20ms/step - loss: 3.2137 - community_output_loss: 2.1417 - label_output_loss: 1.0720 - community_output_accuracy: 0.3438 - label_output_accuracy: 0.3917 - val_loss: 3.1290 - val_community_output_loss: 2.0692 - val_label_output_loss: 1.0598 - val_community_output_accuracy: 0.3494 - val_label_output_accuracy: 0.4176\n",
            "Epoch 4/50\n",
            "323/323 [==============================] - 6s 18ms/step - loss: 3.1165 - community_output_loss: 2.0594 - label_output_loss: 1.0571 - community_output_accuracy: 0.3564 - label_output_accuracy: 0.4174 - val_loss: 3.1134 - val_community_output_loss: 2.0504 - val_label_output_loss: 1.0630 - val_community_output_accuracy: 0.3491 - val_label_output_accuracy: 0.4176\n",
            "Epoch 5/50\n",
            "323/323 [==============================] - 6s 18ms/step - loss: 3.0731 - community_output_loss: 2.0270 - label_output_loss: 1.0461 - community_output_accuracy: 0.3629 - label_output_accuracy: 0.4313 - val_loss: 3.1062 - val_community_output_loss: 2.0521 - val_label_output_loss: 1.0541 - val_community_output_accuracy: 0.3454 - val_label_output_accuracy: 0.4367\n",
            "Epoch 6/50\n",
            "323/323 [==============================] - 6s 18ms/step - loss: 3.0206 - community_output_loss: 1.9854 - label_output_loss: 1.0352 - community_output_accuracy: 0.3693 - label_output_accuracy: 0.4572 - val_loss: 3.0384 - val_community_output_loss: 2.0041 - val_label_output_loss: 1.0343 - val_community_output_accuracy: 0.3603 - val_label_output_accuracy: 0.4610\n",
            "Epoch 7/50\n",
            "323/323 [==============================] - 6s 17ms/step - loss: 2.9494 - community_output_loss: 1.9453 - label_output_loss: 1.0041 - community_output_accuracy: 0.3952 - label_output_accuracy: 0.4825 - val_loss: 2.9519 - val_community_output_loss: 1.9721 - val_label_output_loss: 0.9798 - val_community_output_accuracy: 0.3980 - val_label_output_accuracy: 0.5102\n",
            "Epoch 8/50\n",
            "323/323 [==============================] - 6s 20ms/step - loss: 2.8174 - community_output_loss: 1.8577 - label_output_loss: 0.9598 - community_output_accuracy: 0.4309 - label_output_accuracy: 0.5201 - val_loss: 2.8520 - val_community_output_loss: 1.8903 - val_label_output_loss: 0.9618 - val_community_output_accuracy: 0.4241 - val_label_output_accuracy: 0.5067\n",
            "Epoch 9/50\n",
            "323/323 [==============================] - 6s 18ms/step - loss: 2.7508 - community_output_loss: 1.8118 - label_output_loss: 0.9389 - community_output_accuracy: 0.4399 - label_output_accuracy: 0.5311 - val_loss: 2.9360 - val_community_output_loss: 1.9656 - val_label_output_loss: 0.9704 - val_community_output_accuracy: 0.3645 - val_label_output_accuracy: 0.4891\n",
            "Epoch 10/50\n",
            "323/323 [==============================] - 7s 20ms/step - loss: 2.7185 - community_output_loss: 1.7902 - label_output_loss: 0.9282 - community_output_accuracy: 0.4439 - label_output_accuracy: 0.5470 - val_loss: 2.9576 - val_community_output_loss: 1.9599 - val_label_output_loss: 0.9977 - val_community_output_accuracy: 0.3705 - val_label_output_accuracy: 0.4712\n",
            "Epoch 11/50\n",
            "323/323 [==============================] - 6s 18ms/step - loss: 2.6846 - community_output_loss: 1.7616 - label_output_loss: 0.9230 - community_output_accuracy: 0.4520 - label_output_accuracy: 0.5522 - val_loss: 3.1384 - val_community_output_loss: 2.0879 - val_label_output_loss: 1.0505 - val_community_output_accuracy: 0.2854 - val_label_output_accuracy: 0.4012\n",
            "Epoch 12/50\n",
            "323/323 [==============================] - 7s 21ms/step - loss: 2.6695 - community_output_loss: 1.7509 - label_output_loss: 0.9186 - community_output_accuracy: 0.4530 - label_output_accuracy: 0.5535 - val_loss: 3.0433 - val_community_output_loss: 2.0330 - val_label_output_loss: 1.0103 - val_community_output_accuracy: 0.3079 - val_label_output_accuracy: 0.4591\n",
            "Epoch 13/50\n",
            "323/323 [==============================] - 5s 17ms/step - loss: 2.6419 - community_output_loss: 1.7351 - label_output_loss: 0.9068 - community_output_accuracy: 0.4524 - label_output_accuracy: 0.5571 - val_loss: 2.9078 - val_community_output_loss: 1.9126 - val_label_output_loss: 0.9952 - val_community_output_accuracy: 0.3841 - val_label_output_accuracy: 0.4650\n",
            "Epoch 14/50\n",
            "323/323 [==============================] - 6s 20ms/step - loss: 2.6193 - community_output_loss: 1.7157 - label_output_loss: 0.9036 - community_output_accuracy: 0.4570 - label_output_accuracy: 0.5603 - val_loss: 2.7039 - val_community_output_loss: 1.7671 - val_label_output_loss: 0.9368 - val_community_output_accuracy: 0.4484 - val_label_output_accuracy: 0.5367\n",
            "Epoch 15/50\n",
            "323/323 [==============================] - 6s 20ms/step - loss: 2.5736 - community_output_loss: 1.6753 - label_output_loss: 0.8983 - community_output_accuracy: 0.4854 - label_output_accuracy: 0.5644 - val_loss: 2.8808 - val_community_output_loss: 1.8573 - val_label_output_loss: 1.0235 - val_community_output_accuracy: 0.4266 - val_label_output_accuracy: 0.4447\n",
            "Epoch 16/50\n",
            "323/323 [==============================] - 6s 17ms/step - loss: 2.5322 - community_output_loss: 1.6393 - label_output_loss: 0.8929 - community_output_accuracy: 0.4976 - label_output_accuracy: 0.5688 - val_loss: 3.4268 - val_community_output_loss: 2.1981 - val_label_output_loss: 1.2287 - val_community_output_accuracy: 0.2717 - val_label_output_accuracy: 0.4484\n",
            "Epoch 17/50\n",
            "323/323 [==============================] - 6s 20ms/step - loss: 2.5016 - community_output_loss: 1.6150 - label_output_loss: 0.8866 - community_output_accuracy: 0.5114 - label_output_accuracy: 0.5783 - val_loss: 3.1298 - val_community_output_loss: 2.0814 - val_label_output_loss: 1.0484 - val_community_output_accuracy: 0.2591 - val_label_output_accuracy: 0.4747\n",
            "Epoch 18/50\n",
            "323/323 [==============================] - 6s 17ms/step - loss: 2.4708 - community_output_loss: 1.5943 - label_output_loss: 0.8764 - community_output_accuracy: 0.5174 - label_output_accuracy: 0.5791 - val_loss: 3.3021 - val_community_output_loss: 2.2419 - val_label_output_loss: 1.0602 - val_community_output_accuracy: 0.3486 - val_label_output_accuracy: 0.4390\n",
            "Epoch 19/50\n",
            "323/323 [==============================] - 7s 21ms/step - loss: 2.4457 - community_output_loss: 1.5743 - label_output_loss: 0.8713 - community_output_accuracy: 0.5215 - label_output_accuracy: 0.5906 - val_loss: 3.0303 - val_community_output_loss: 1.9836 - val_label_output_loss: 1.0467 - val_community_output_accuracy: 0.3042 - val_label_output_accuracy: 0.4258\n",
            "Epoch 20/50\n",
            "323/323 [==============================] - 5s 16ms/step - loss: 2.4242 - community_output_loss: 1.5600 - label_output_loss: 0.8642 - community_output_accuracy: 0.5275 - label_output_accuracy: 0.5944 - val_loss: 3.4816 - val_community_output_loss: 2.4301 - val_label_output_loss: 1.0515 - val_community_output_accuracy: 0.2452 - val_label_output_accuracy: 0.4615\n",
            "Epoch 21/50\n",
            "323/323 [==============================] - 6s 20ms/step - loss: 2.4080 - community_output_loss: 1.5488 - label_output_loss: 0.8592 - community_output_accuracy: 0.5329 - label_output_accuracy: 0.5968 - val_loss: 2.6987 - val_community_output_loss: 1.7359 - val_label_output_loss: 0.9628 - val_community_output_accuracy: 0.4563 - val_label_output_accuracy: 0.5094\n",
            "Epoch 22/50\n",
            "323/323 [==============================] - 5s 16ms/step - loss: 2.3780 - community_output_loss: 1.5287 - label_output_loss: 0.8492 - community_output_accuracy: 0.5354 - label_output_accuracy: 0.6034 - val_loss: 3.3357 - val_community_output_loss: 2.0938 - val_label_output_loss: 1.2420 - val_community_output_accuracy: 0.2519 - val_label_output_accuracy: 0.3486\n",
            "Epoch 23/50\n",
            "323/323 [==============================] - 6s 18ms/step - loss: 2.3528 - community_output_loss: 1.5171 - label_output_loss: 0.8357 - community_output_accuracy: 0.5427 - label_output_accuracy: 0.6153 - val_loss: 2.7987 - val_community_output_loss: 1.8058 - val_label_output_loss: 0.9929 - val_community_output_accuracy: 0.4141 - val_label_output_accuracy: 0.4968\n",
            "Epoch 24/50\n",
            "323/323 [==============================] - 6s 20ms/step - loss: 2.3328 - community_output_loss: 1.4973 - label_output_loss: 0.8355 - community_output_accuracy: 0.5483 - label_output_accuracy: 0.6160 - val_loss: 3.4373 - val_community_output_loss: 2.3203 - val_label_output_loss: 1.1171 - val_community_output_accuracy: 0.2241 - val_label_output_accuracy: 0.3864\n",
            "Epoch 25/50\n",
            "323/323 [==============================] - 6s 18ms/step - loss: 2.3025 - community_output_loss: 1.4788 - label_output_loss: 0.8237 - community_output_accuracy: 0.5527 - label_output_accuracy: 0.6257 - val_loss: 3.0211 - val_community_output_loss: 1.9830 - val_label_output_loss: 1.0382 - val_community_output_accuracy: 0.3117 - val_label_output_accuracy: 0.4464\n",
            "Epoch 26/50\n",
            "323/323 [==============================] - 6s 19ms/step - loss: 2.2868 - community_output_loss: 1.4700 - label_output_loss: 0.8168 - community_output_accuracy: 0.5580 - label_output_accuracy: 0.6269 - val_loss: 2.9099 - val_community_output_loss: 1.9203 - val_label_output_loss: 0.9896 - val_community_output_accuracy: 0.3551 - val_label_output_accuracy: 0.5027\n",
            "Epoch 27/50\n",
            "323/323 [==============================] - 6s 17ms/step - loss: 2.2545 - community_output_loss: 1.4498 - label_output_loss: 0.8047 - community_output_accuracy: 0.5645 - label_output_accuracy: 0.6344 - val_loss: 2.8742 - val_community_output_loss: 1.8807 - val_label_output_loss: 0.9936 - val_community_output_accuracy: 0.3794 - val_label_output_accuracy: 0.5084\n",
            "Epoch 28/50\n",
            "323/323 [==============================] - 7s 21ms/step - loss: 2.2372 - community_output_loss: 1.4384 - label_output_loss: 0.7987 - community_output_accuracy: 0.5648 - label_output_accuracy: 0.6374 - val_loss: 3.7120 - val_community_output_loss: 2.4741 - val_label_output_loss: 1.2379 - val_community_output_accuracy: 0.2060 - val_label_output_accuracy: 0.3486\n",
            "Epoch 29/50\n",
            "323/323 [==============================] - 6s 17ms/step - loss: 2.2145 - community_output_loss: 1.4272 - label_output_loss: 0.7873 - community_output_accuracy: 0.5697 - label_output_accuracy: 0.6435 - val_loss: 2.7953 - val_community_output_loss: 1.8273 - val_label_output_loss: 0.9680 - val_community_output_accuracy: 0.4283 - val_label_output_accuracy: 0.5333\n",
            "Epoch 30/50\n",
            "323/323 [==============================] - 7s 20ms/step - loss: 2.1853 - community_output_loss: 1.4048 - label_output_loss: 0.7805 - community_output_accuracy: 0.5815 - label_output_accuracy: 0.6522 - val_loss: 2.9999 - val_community_output_loss: 1.9840 - val_label_output_loss: 1.0159 - val_community_output_accuracy: 0.3449 - val_label_output_accuracy: 0.5005\n",
            "Epoch 31/50\n",
            "323/323 [==============================] - 6s 17ms/step - loss: 2.1713 - community_output_loss: 1.3935 - label_output_loss: 0.7779 - community_output_accuracy: 0.5849 - label_output_accuracy: 0.6518 - val_loss: 2.8843 - val_community_output_loss: 1.8774 - val_label_output_loss: 1.0069 - val_community_output_accuracy: 0.3886 - val_label_output_accuracy: 0.4985\n",
            "Epoch 32/50\n",
            "323/323 [==============================] - 6s 18ms/step - loss: 2.1478 - community_output_loss: 1.3860 - label_output_loss: 0.7618 - community_output_accuracy: 0.5856 - label_output_accuracy: 0.6626 - val_loss: 2.7179 - val_community_output_loss: 1.7568 - val_label_output_loss: 0.9611 - val_community_output_accuracy: 0.4469 - val_label_output_accuracy: 0.5370\n",
            "Epoch 33/50\n",
            "323/323 [==============================] - 6s 19ms/step - loss: 2.1243 - community_output_loss: 1.3666 - label_output_loss: 0.7577 - community_output_accuracy: 0.5901 - label_output_accuracy: 0.6631 - val_loss: 2.7861 - val_community_output_loss: 1.7976 - val_label_output_loss: 0.9885 - val_community_output_accuracy: 0.4290 - val_label_output_accuracy: 0.5275\n",
            "Epoch 34/50\n",
            "323/323 [==============================] - 5s 17ms/step - loss: 2.0970 - community_output_loss: 1.3516 - label_output_loss: 0.7455 - community_output_accuracy: 0.5970 - label_output_accuracy: 0.6712 - val_loss: 3.0665 - val_community_output_loss: 1.9810 - val_label_output_loss: 1.0855 - val_community_output_accuracy: 0.3697 - val_label_output_accuracy: 0.4821\n",
            "Epoch 35/50\n",
            "323/323 [==============================] - 6s 20ms/step - loss: 2.0760 - community_output_loss: 1.3310 - label_output_loss: 0.7450 - community_output_accuracy: 0.6024 - label_output_accuracy: 0.6752 - val_loss: 3.2183 - val_community_output_loss: 2.1420 - val_label_output_loss: 1.0762 - val_community_output_accuracy: 0.3159 - val_label_output_accuracy: 0.4643\n",
            "Epoch 36/50\n",
            "323/323 [==============================] - 5s 17ms/step - loss: 2.0681 - community_output_loss: 1.3294 - label_output_loss: 0.7386 - community_output_accuracy: 0.6006 - label_output_accuracy: 0.6735 - val_loss: 3.0819 - val_community_output_loss: 2.0091 - val_label_output_loss: 1.0729 - val_community_output_accuracy: 0.3576 - val_label_output_accuracy: 0.4873\n",
            "Epoch 37/50\n",
            "323/323 [==============================] - 7s 21ms/step - loss: 2.0559 - community_output_loss: 1.3233 - label_output_loss: 0.7326 - community_output_accuracy: 0.6017 - label_output_accuracy: 0.6769 - val_loss: 3.5759 - val_community_output_loss: 2.3572 - val_label_output_loss: 1.2186 - val_community_output_accuracy: 0.2695 - val_label_output_accuracy: 0.3856\n",
            "Epoch 38/50\n",
            "323/323 [==============================] - 5s 16ms/step - loss: 2.0284 - community_output_loss: 1.3065 - label_output_loss: 0.7219 - community_output_accuracy: 0.6122 - label_output_accuracy: 0.6810 - val_loss: 2.9452 - val_community_output_loss: 1.9141 - val_label_output_loss: 1.0311 - val_community_output_accuracy: 0.4129 - val_label_output_accuracy: 0.5107\n",
            "Epoch 39/50\n",
            "323/323 [==============================] - 6s 20ms/step - loss: 2.0051 - community_output_loss: 1.2906 - label_output_loss: 0.7145 - community_output_accuracy: 0.6159 - label_output_accuracy: 0.6863 - val_loss: 3.1120 - val_community_output_loss: 2.0555 - val_label_output_loss: 1.0565 - val_community_output_accuracy: 0.3581 - val_label_output_accuracy: 0.4983\n",
            "Epoch 40/50\n",
            "323/323 [==============================] - 6s 17ms/step - loss: 1.9897 - community_output_loss: 1.2858 - label_output_loss: 0.7039 - community_output_accuracy: 0.6178 - label_output_accuracy: 0.6938 - val_loss: 3.1575 - val_community_output_loss: 2.0552 - val_label_output_loss: 1.1022 - val_community_output_accuracy: 0.3556 - val_label_output_accuracy: 0.4749\n",
            "Epoch 41/50\n",
            "323/323 [==============================] - 6s 19ms/step - loss: 1.9888 - community_output_loss: 1.2789 - label_output_loss: 0.7099 - community_output_accuracy: 0.6193 - label_output_accuracy: 0.6928 - val_loss: 3.3420 - val_community_output_loss: 2.2125 - val_label_output_loss: 1.1295 - val_community_output_accuracy: 0.3102 - val_label_output_accuracy: 0.4623\n",
            "Epoch 42/50\n",
            "323/323 [==============================] - 6s 19ms/step - loss: 1.9625 - community_output_loss: 1.2668 - label_output_loss: 0.6957 - community_output_accuracy: 0.6220 - label_output_accuracy: 0.7049 - val_loss: 2.8948 - val_community_output_loss: 1.8543 - val_label_output_loss: 1.0405 - val_community_output_accuracy: 0.4434 - val_label_output_accuracy: 0.5273\n",
            "Epoch 43/50\n",
            "323/323 [==============================] - 5s 17ms/step - loss: 1.9496 - community_output_loss: 1.2586 - label_output_loss: 0.6910 - community_output_accuracy: 0.6253 - label_output_accuracy: 0.6992 - val_loss: 3.5159 - val_community_output_loss: 2.3031 - val_label_output_loss: 1.2128 - val_community_output_accuracy: 0.2868 - val_label_output_accuracy: 0.4273\n",
            "Epoch 44/50\n",
            "323/323 [==============================] - 6s 20ms/step - loss: 1.9408 - community_output_loss: 1.2515 - label_output_loss: 0.6893 - community_output_accuracy: 0.6315 - label_output_accuracy: 0.6972 - val_loss: 3.1348 - val_community_output_loss: 2.0909 - val_label_output_loss: 1.0439 - val_community_output_accuracy: 0.3531 - val_label_output_accuracy: 0.5164\n",
            "Epoch 45/50\n",
            "323/323 [==============================] - 5s 17ms/step - loss: 1.9153 - community_output_loss: 1.2335 - label_output_loss: 0.6818 - community_output_accuracy: 0.6310 - label_output_accuracy: 0.7056 - val_loss: 3.0011 - val_community_output_loss: 1.9413 - val_label_output_loss: 1.0598 - val_community_output_accuracy: 0.4052 - val_label_output_accuracy: 0.5149\n",
            "Epoch 46/50\n",
            "323/323 [==============================] - 6s 20ms/step - loss: 1.9034 - community_output_loss: 1.2289 - label_output_loss: 0.6745 - community_output_accuracy: 0.6335 - label_output_accuracy: 0.7126 - val_loss: 2.8929 - val_community_output_loss: 1.8307 - val_label_output_loss: 1.0622 - val_community_output_accuracy: 0.4556 - val_label_output_accuracy: 0.5273\n",
            "Epoch 47/50\n",
            "323/323 [==============================] - 6s 17ms/step - loss: 1.8960 - community_output_loss: 1.2203 - label_output_loss: 0.6757 - community_output_accuracy: 0.6376 - label_output_accuracy: 0.7110 - val_loss: 4.2389 - val_community_output_loss: 2.2490 - val_label_output_loss: 1.9899 - val_community_output_accuracy: 0.2911 - val_label_output_accuracy: 0.4682\n",
            "Epoch 48/50\n",
            "323/323 [==============================] - 6s 18ms/step - loss: 1.8856 - community_output_loss: 1.2196 - label_output_loss: 0.6660 - community_output_accuracy: 0.6383 - label_output_accuracy: 0.7160 - val_loss: 3.1584 - val_community_output_loss: 2.0770 - val_label_output_loss: 1.0814 - val_community_output_accuracy: 0.3625 - val_label_output_accuracy: 0.5149\n",
            "Epoch 49/50\n",
            "323/323 [==============================] - 6s 18ms/step - loss: 1.8823 - community_output_loss: 1.2151 - label_output_loss: 0.6673 - community_output_accuracy: 0.6432 - label_output_accuracy: 0.7201 - val_loss: 3.0045 - val_community_output_loss: 1.9389 - val_label_output_loss: 1.0656 - val_community_output_accuracy: 0.4266 - val_label_output_accuracy: 0.5305\n",
            "Epoch 50/50\n",
            "323/323 [==============================] - 5s 17ms/step - loss: 1.8505 - community_output_loss: 1.2009 - label_output_loss: 0.6496 - community_output_accuracy: 0.6440 - label_output_accuracy: 0.7239 - val_loss: 3.0131 - val_community_output_loss: 1.9192 - val_label_output_loss: 1.0938 - val_community_output_accuracy: 0.4283 - val_label_output_accuracy: 0.5166\n"
          ]
        }
      ]
    }
  ]
}