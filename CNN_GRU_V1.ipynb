{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnF0xGd71RoqZqEyU0N9VP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sarvesh1814/HateXplain/blob/Sarvesh/CNN_GRU_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLUfaxMXysON",
        "outputId": "6cfd22cb-5b0e-43a6-bafa-b20871c1a0d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, GRU, Dense, Dropout\n",
        "import numpy as np\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from wordcloud import WordCloud\n",
        "from gensim.models import Word2Vec\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "zIZ8Y9UgyTcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import gensim\n",
        "import spacy\n",
        "import nltk\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, GRU, Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "Q2jm9eXj1Zup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the pre-trained GloVe word embeddings\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE5EkqhbyWFs",
        "outputId": "956f0776-06ce-45d4-ffed-f6017dc8b627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-11 10:10:11--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2023-04-11 10:10:11--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-04-11 10:10:12--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.03MB/s    in 2m 39s  \n",
            "\n",
            "2023-04-11 10:12:51 (5.16 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Reproducibility/Sample Model/HateXplain2.csv\")"
      ],
      "metadata": {
        "id": "1b1yoLDw153l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df[['post_tokens',\t'Target_cat',\t'Label_cat',\t'final_rationales']]\n",
        "data['post_tokens'] = data['post_tokens'].apply(lambda x: eval(x))\n",
        "for i in range(len(data)):\n",
        "  \n",
        "  sentence =\"\"\n",
        "  for j in (data['post_tokens'].iloc[i]):\n",
        "    \n",
        "    sentence += j +\" \"\n",
        "    \n",
        "  data['post_tokens'].iloc[i] = sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiZs90jR1_uB",
        "outputId": "789730ec-168f-48b8-bd9c-6ff88c640834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-5f0ee8932d8a>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['post_tokens'] = data['post_tokens'].apply(lambda x: eval(x))\n",
            "<ipython-input-19-5f0ee8932d8a>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['post_tokens'].iloc[i] = sentence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {'hatespeech': 0, 'normal': 1, 'offensive': 2}\n",
        "labels = data[\"Label_cat\"].apply(lambda x: label_map[x])"
      ],
      "metadata": {
        "id": "gNrV0SsR2CTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 10000\n",
        "maxlen = 100\n",
        "\n",
        "# Tokenize the text data and convert it to sequences of integers\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(df['post_tokens'])\n",
        "sequences = tokenizer.texts_to_sequences(df['post_tokens'])\n",
        "X = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "# Define the target labels\n",
        "y = pd.get_dummies(df['Label_cat']).values\n"
      ],
      "metadata": {
        "id": "zNIUNUvv1zmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained GloVe embeddings\n",
        "embedding_dict = {}\n",
        "with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_dict[word] = vector\n",
        "\n",
        "# Initialize the embedding matrix with pre-trained GloVe embeddings\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(max_words, len(word_index) + 1)\n",
        "embedding_matrix = np.zeros((num_words, 100))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_words:\n",
        "        continue\n",
        "    embedding_vector = embedding_dict.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n"
      ],
      "metadata": {
        "id": "ftMNfY-u2JkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_words, 100, weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
        "model.add(Conv1D(32, 7, activation='relu'))\n",
        "model.add(MaxPooling1D(5))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(GRU(64, dropout=0.5, recurrent_dropout=0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=RMSprop(lr=1e-4), loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO4PZEU52WfP",
        "outputId": "c9e999de-6db1-4786-bbcf-47a7c573b7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "504/504 [==============================] - 28s 49ms/step - loss: 1.0673 - acc: 0.4202 - val_loss: 1.1600 - val_acc: 0.2268\n",
            "Epoch 2/10\n",
            "504/504 [==============================] - 25s 49ms/step - loss: 1.0490 - acc: 0.4278 - val_loss: 1.1610 - val_acc: 0.2268\n",
            "Epoch 3/10\n",
            "504/504 [==============================] - 23s 45ms/step - loss: 1.0396 - acc: 0.4310 - val_loss: 1.1643 - val_acc: 0.2953\n",
            "Epoch 4/10\n",
            "504/504 [==============================] - 25s 49ms/step - loss: 1.0373 - acc: 0.4309 - val_loss: 1.1619 - val_acc: 0.2970\n",
            "Epoch 5/10\n",
            "504/504 [==============================] - 24s 48ms/step - loss: 1.0322 - acc: 0.4327 - val_loss: 1.1635 - val_acc: 0.2953\n",
            "Epoch 6/10\n",
            "504/504 [==============================] - 22s 44ms/step - loss: 1.0324 - acc: 0.4352 - val_loss: 1.1642 - val_acc: 0.2275\n",
            "Epoch 7/10\n",
            "504/504 [==============================] - 24s 48ms/step - loss: 1.0323 - acc: 0.4291 - val_loss: 1.1556 - val_acc: 0.2988\n",
            "Epoch 8/10\n",
            "504/504 [==============================] - 29s 58ms/step - loss: 1.0321 - acc: 0.4341 - val_loss: 1.1587 - val_acc: 0.2985\n",
            "Epoch 9/10\n",
            "504/504 [==============================] - 30s 59ms/step - loss: 1.0325 - acc: 0.4332 - val_loss: 1.1606 - val_acc: 0.2995\n",
            "Epoch 10/10\n",
            "504/504 [==============================] - 23s 46ms/step - loss: 1.0310 - acc: 0.4349 - val_loss: 1.1605 - val_acc: 0.2978\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5935541ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}