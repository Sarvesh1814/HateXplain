{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZNy3RwSx21B52CBZikNSD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sarvesh1814/HateXplain/blob/Sarvesh/CNN_GRU_V7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLUfaxMXysON",
        "outputId": "a89f2842-70d3-4b55-9986-574727bac2b4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, GRU, Dense, Dropout\n",
        "import numpy as np\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from wordcloud import WordCloud\n",
        "from gensim.models import Word2Vec\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "zIZ8Y9UgyTcd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import gensim\n",
        "import spacy\n",
        "import nltk\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, GRU, Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import RMSprop,Adam\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "Q2jm9eXj1Zup"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the pre-trained GloVe word embeddings\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE5EkqhbyWFs",
        "outputId": "69c976e4-971b-4cb6-f875-782b8e5467f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-13 10:19:53--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2023-04-13 10:19:53--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-04-13 10:19:53--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n",
            "\n",
            "2023-04-13 10:22:32 (5.18 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Reproducibility/Sample Model/HateXplain2.csv\")"
      ],
      "metadata": {
        "id": "1b1yoLDw153l"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df[['post_tokens',\t'Target_cat',\t'Label_cat',\t'final_rationales']]\n",
        "data['post_tokens'] = data['post_tokens'].apply(lambda x: eval(x))\n",
        "for i in range(len(data)):\n",
        "  \n",
        "  sentence =\"\"\n",
        "  for j in (data['post_tokens'].iloc[i]):\n",
        "    \n",
        "    sentence += j +\" \"\n",
        "    \n",
        "  data['post_tokens'].iloc[i] = sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiZs90jR1_uB",
        "outputId": "798db8b2-781c-44a7-aa66-6d3397da3d1c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-5f0ee8932d8a>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['post_tokens'] = data['post_tokens'].apply(lambda x: eval(x))\n",
            "<ipython-input-6-5f0ee8932d8a>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['post_tokens'].iloc[i] = sentence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {'hatespeech': 0, 'normal': 1, 'offensive': 2}\n",
        "labels = data[\"Label_cat\"].apply(lambda x: label_map[x])"
      ],
      "metadata": {
        "id": "gNrV0SsR2CTa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y2 = label_encoder.fit_transform(data['Target_cat'])"
      ],
      "metadata": {
        "id": "_bPhgPdIOfdj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 30000\n",
        "maxlen = 100\n",
        "\n",
        "# Tokenize the text data and convert it to sequences of integers\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(df['post_tokens'])\n",
        "sequences = tokenizer.texts_to_sequences(df['post_tokens'])\n",
        "X = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "# Define the target labels\n",
        "y1 = pd.get_dummies(df['Label_cat']).values\n",
        "y2 = to_categorical(y2, num_classes=21)"
      ],
      "metadata": {
        "id": "zNIUNUvv1zmc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFtuaXqNQuvo",
        "outputId": "964ccb1f-fad7-44c1-a011-7d5aa7710d4b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       ...,\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained GloVe embeddings\n",
        "embedding_dict = {}\n",
        "with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_dict[word] = vector\n",
        "\n",
        "# Initialize the embedding matrix with pre-trained GloVe embeddings\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(max_words, len(word_index) + 1)\n",
        "embedding_matrix = np.zeros((num_words, 100))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_words:\n",
        "        continue\n",
        "    embedding_vector = embedding_dict.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n"
      ],
      "metadata": {
        "id": "ftMNfY-u2JkW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Arichtecture"
      ],
      "metadata": {
        "id": "1XAU2Nmp9W45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "from keras.models import Model\n",
        "model1 = Sequential()\n",
        "model1.add(Embedding(num_words, 100, weights=[embedding_matrix], input_length=maxlen, trainable=True))\n",
        "model1.add(Conv1D(64, 7, activation='relu'))\n",
        "model1.add(MaxPooling1D(2))\n",
        "model1.add(Dropout(0.1))\n",
        "model1.add(Conv1D(128, 7, activation='relu'))\n",
        "model1.add(MaxPooling1D(2))\n",
        "model1.add(GRU(128, dropout=0.2, recurrent_dropout=0.1))\n",
        "model1.add(Dense(128, activation='relu'))\n",
        "model1.add(Dense(64, activation='relu'))\n",
        "model2 = Dense(3, activation='softmax')(model1.output)\n",
        "model3 = Dense(21, activation='softmax')(model1.output)\n",
        "\n",
        "model = Model(inputs=model1.input, outputs=[model2, model3])\n",
        "# Compile the model1\n",
        "model.compile(optimizer=RMSprop(lr=1e-2), loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "# Train the model1\n",
        "history=model.fit(X, [y1, y2], epochs=10, batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9Dh14KZ5UE4",
        "outputId": "50c15ac7-5478-4c68-e1ef-88402fb2c56c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "252/252 [==============================] - 54s 198ms/step - loss: 3.0492 - dense_10_loss: 1.0373 - dense_11_loss: 2.0119 - dense_10_acc: 0.4788 - dense_11_acc: 0.4141 - val_loss: 3.3039 - val_dense_10_loss: 1.0447 - val_dense_11_loss: 2.2592 - val_dense_10_acc: 0.3459 - val_dense_11_acc: 0.2400\n",
            "Epoch 2/10\n",
            "252/252 [==============================] - 51s 203ms/step - loss: 2.6801 - dense_10_loss: 0.8916 - dense_11_loss: 1.7885 - dense_10_acc: 0.5825 - dense_11_acc: 0.4734 - val_loss: 3.3233 - val_dense_10_loss: 1.1025 - val_dense_11_loss: 2.2209 - val_dense_10_acc: 0.3730 - val_dense_11_acc: 0.2734\n",
            "Epoch 3/10\n",
            "252/252 [==============================] - 49s 193ms/step - loss: 2.5486 - dense_10_loss: 0.8532 - dense_11_loss: 1.6954 - dense_10_acc: 0.6075 - dense_11_acc: 0.4988 - val_loss: 3.2736 - val_dense_10_loss: 1.0989 - val_dense_11_loss: 2.1747 - val_dense_10_acc: 0.3806 - val_dense_11_acc: 0.2747\n",
            "Epoch 4/10\n",
            "252/252 [==============================] - 51s 204ms/step - loss: 2.4677 - dense_10_loss: 0.8225 - dense_11_loss: 1.6452 - dense_10_acc: 0.6266 - dense_11_acc: 0.5096 - val_loss: 3.2263 - val_dense_10_loss: 1.0696 - val_dense_11_loss: 2.1567 - val_dense_10_acc: 0.3906 - val_dense_11_acc: 0.2888\n",
            "Epoch 5/10\n",
            "252/252 [==============================] - 49s 195ms/step - loss: 2.4136 - dense_10_loss: 0.8067 - dense_11_loss: 1.6070 - dense_10_acc: 0.6308 - dense_11_acc: 0.5150 - val_loss: 3.3525 - val_dense_10_loss: 1.0933 - val_dense_11_loss: 2.2592 - val_dense_10_acc: 0.4233 - val_dense_11_acc: 0.2871\n",
            "Epoch 6/10\n",
            "252/252 [==============================] - 49s 196ms/step - loss: 2.3970 - dense_10_loss: 0.8021 - dense_11_loss: 1.5949 - dense_10_acc: 0.6367 - dense_11_acc: 0.5211 - val_loss: 3.5134 - val_dense_10_loss: 1.2002 - val_dense_11_loss: 2.3132 - val_dense_10_acc: 0.3851 - val_dense_11_acc: 0.2873\n",
            "Epoch 7/10\n",
            "252/252 [==============================] - 51s 202ms/step - loss: 2.3622 - dense_10_loss: 0.7856 - dense_11_loss: 1.5766 - dense_10_acc: 0.6486 - dense_11_acc: 0.5257 - val_loss: 3.2542 - val_dense_10_loss: 1.0831 - val_dense_11_loss: 2.1711 - val_dense_10_acc: 0.4201 - val_dense_11_acc: 0.2968\n",
            "Epoch 8/10\n",
            "252/252 [==============================] - 51s 203ms/step - loss: 2.3598 - dense_10_loss: 0.7861 - dense_11_loss: 1.5737 - dense_10_acc: 0.6462 - dense_11_acc: 0.5293 - val_loss: 3.3547 - val_dense_10_loss: 1.1038 - val_dense_11_loss: 2.2509 - val_dense_10_acc: 0.4288 - val_dense_11_acc: 0.3052\n",
            "Epoch 9/10\n",
            "252/252 [==============================] - 52s 208ms/step - loss: 2.2833 - dense_10_loss: 0.7689 - dense_11_loss: 1.5144 - dense_10_acc: 0.6603 - dense_11_acc: 0.5541 - val_loss: 3.5226 - val_dense_10_loss: 1.1939 - val_dense_11_loss: 2.3287 - val_dense_10_acc: 0.4171 - val_dense_11_acc: 0.3057\n",
            "Epoch 10/10\n",
            "252/252 [==============================] - 50s 198ms/step - loss: 2.2492 - dense_10_loss: 0.7572 - dense_11_loss: 1.4920 - dense_10_acc: 0.6591 - dense_11_acc: 0.5643 - val_loss: 3.2721 - val_dense_10_loss: 1.0782 - val_dense_11_loss: 2.1939 - val_dense_10_acc: 0.4474 - val_dense_11_acc: 0.3308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted labels\n",
        "y_pred1, y_pred2 = model.predict(X)\n",
        "\n",
        "# Convert the labels from one-hot encoding to integers\n",
        "y_pred1 = np.argmax(y_pred1, axis=1)\n",
        "y_pred2 = np.argmax(y_pred2, axis=1)\n",
        "y_test_int1 = np.argmax(y1, axis=1)\n",
        "y_test_int2 = np.argmax(y2, axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAR3_Jxwaa6i",
        "outputId": "db4f9cea-4918-46b3-e4fb-20438a1a25c1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "630/630 [==============================] - 14s 22ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(\"Classification report for model2:\")\n",
        "print(classification_report(y_test_int2,y_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUyyHYFQalM9",
        "outputId": "eab68bbd-673b-4d01-e795-bc040a1d9005"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for model2:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.56      0.65      3037\n",
            "           1       0.00      0.00      0.00       583\n",
            "           2       0.00      0.00      0.00       326\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.00      0.00      0.00       334\n",
            "           5       0.00      0.00      0.00        33\n",
            "           6       0.00      0.00      0.00        48\n",
            "           7       0.00      0.00      0.00        10\n",
            "           8       0.00      0.00      0.00        15\n",
            "           9       0.00      0.00      0.00       222\n",
            "          10       0.22      0.06      0.09      1576\n",
            "          11       0.00      0.00      0.00         8\n",
            "          12       0.00      0.00      0.00         4\n",
            "          13       0.47      0.40      0.43      1633\n",
            "          14       0.50      0.64      0.56      1424\n",
            "          15       0.00      0.00      0.00        89\n",
            "          16       0.00      0.00      0.00         9\n",
            "          17       0.50      0.90      0.64      7109\n",
            "          18       0.00      0.00      0.00      1218\n",
            "          19       0.68      0.45      0.54       962\n",
            "          20       0.58      0.31      0.41      1507\n",
            "\n",
            "    accuracy                           0.53     20148\n",
            "   macro avg       0.18      0.16      0.16     20148\n",
            "weighted avg       0.46      0.53      0.46     20148\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification report for model3:\")\n",
        "print(classification_report(y_test_int1,y_pred1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_FntwmwaxiD",
        "outputId": "2497911c-2243-4124-a00f-83afc2827c1f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for model3:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.67      0.68      5934\n",
            "           1       0.63      0.79      0.70      7814\n",
            "           2       0.51      0.38      0.43      6400\n",
            "\n",
            "    accuracy                           0.62     20148\n",
            "   macro avg       0.61      0.61      0.61     20148\n",
            "weighted avg       0.61      0.62      0.61     20148\n",
            "\n"
          ]
        }
      ]
    }
  ]
}